{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy \n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "spaCy is a free and open-source NLP library. It is widely used due to its advanced and versatile characteristics. Before we get into how NER works in spaCy, it's important to understand what a Named Entity Recognizer is.\n",
    "\n",
    "A standard NLP task is named entity recognition, which can recognize entities discussed in a written document. A model that can perform this task is a Named Entity Recognizer. It should be able to recognize named entities such as \"New Zealand,\" \"John,\" \"Auckland,\" and so on, and classify them as PERSON, LOCATION, and so on. It is a highly handy tool that supports in the extraction of information. The pipeline component ner implements NER in sapCy. By default, most models have it in their processing pipeline.\n",
    "\n",
    "\n",
    "First, we'll instal the packages and check to see if the ner model is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load a spacy model and check if it has ner (pre trained model for Named Entity Recognizer)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, NER is in the pipeline and we can proceed to categorize our entities based on the baseline mode, or already a pre trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen, spaCy features a built-in NER pipeline. It does a good job, although it isn't always 100% correct for our text. Depending on the context, a word can be classified as a PERSON or an ORG. Also, the category we require might not be available in spaCy.\n",
    "\n",
    "Let's have a look at how the NER handles survey responses by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the survey file\n",
    "survey_responses = pd.read_csv(\"Survey response sample data.csv\")\n",
    "survey_responses = pd.DataFrame(survey_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "label = []\n",
    "for i in range(0,len(survey_responses)):\n",
    "    default_entities = nlp(survey_responses.iloc[i,1])\n",
    "    for ent in default_entities.ents:\n",
    "        text.append(ent.text)\n",
    "        label.append(ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gentlemen, Outlander</td>\n",
       "      <td>WORK_OF_ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dublin</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neon</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Undoing</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CB Strike</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>British</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Text        Label\n",
       "0  Gentlemen, Outlander  WORK_OF_ART\n",
       "1                London          GPE\n",
       "2                Dublin          GPE\n",
       "3                  Neon          ORG\n",
       "4               Undoing          ORG\n",
       "5             CB Strike       PERSON\n",
       "6               British         NORP"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output = pd.DataFrame({'Text':text,'Label':label})\n",
    "Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the table above, the default NER recognizes some of the entities incorrectly. CB Strike, for example, is classified as a PERSON, while Undoing is classified as an ORG. There are also a lot more movie or show titles that haven't been categorized in the WORK OF ART category, such as Fear of the Walking Dead, Supernatural, and others. In such a circumstance, we will need to update and train the NER model in accordance with the context and requirements. How to do it is demonstrated in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the Recognizer for Named Entities\n",
    "\n",
    "We saw why we need to update and train the NER in the previous section. Let's get started and figure out how to do it.\n",
    "\n",
    "It is our responsibility to ensure that the NER identifies the movie titles as MOVIE. To do so, we'll need to provide training examples that the NER can use to learn for future samples. Let's do this by updating an existing pre-trained spaCy model with newer samples. Let's start by loading a pre-built spaCY model with a ner component. Then use the get_pipe() method to get the Named Entity Recognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pre-existing spacy model\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#getting the pipeline component\n",
    "ner = nlp.get_pipe(\"ner\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To substantially improve the system, we will need to submit a large number of instances in order to update the pre-trained model with new examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the training examples\n",
    "\n",
    "\n",
    "Training data is accepted as a list of tuples by spaCy.\n",
    "\n",
    "The text and dictionary should be included in each tuple. The start and end indices of the identified entity in the text, as well as the category or label of the named entity, should be stored in the dictionary.\n",
    "\n",
    "As an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, creating a trining set manually is exhausting and consumes a lot of time. I am using a tool developed by https://github.com/ManivannanMurugavel/spacy-ner-annotator to create a training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must add these labels to pipeline's ner.add_label() method. The following code demonstrates this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the converter script\n",
    "import convert_spacy_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training format\n",
    "train_data = [('Fear the walking dead,Supernatural (huge fan and sad it has finished),The Gentlemen, Outlander', {'entities': [(85, 94, 'Movie_Show_Titles'), (70, 83, 'Movie_Show_Titles'), (22, 34, 'Movie_Show_Titles'), (0, 21, 'Movie_Show_Titles')]}), ('Miss scarlet and the duke,knifes out,Dublin murders', {'entities': [(51, 37, 'Movie_Show_Titles'), (36, 26, 'Movie_Show_Titles'), (25, 0, 'Movie_Show_Titles')]}), ('A lot!-good doctor-gangs of London�\\xa0- the gentleman-ma�\\xa0-spies in disguise�\\xa0', {'entities': [(73, 55, 'Movie_Show_Titles'), (53, 51, 'Movie_Show_Titles'), (50, 37, 'Movie_Show_Titles'), (34, 19, 'Movie_Show_Titles'), (18, 7, 'Movie_Show_Titles')]}), ('The Undoing,Game of thrones,Outlander, Vikings,CB Strike (and most all British dramas) Westworld', {'entities': [(56, 47, 'Movie_Show_Titles'), (39, 46, 'Movie_Show_Titles'), (37, 28, 'Movie_Show_Titles'), (27, 12, 'Movie_Show_Titles'), (11, 0, 'Movie_Show_Titles')]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding labels to the ner\n",
    "for _, __annotations__ in train_data:\n",
    "    for ent in __annotations__.get('entities'):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to put the NER through its paces with these examples. However, remember from part ner that the model contains additional pipeline components before we train. These elements should not be harmed during training. As a result, we use the nlp.disable_pipes() method to disable the other pipeline components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable pipeline components you dont need to change\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unaffected pipes should now be disabled while training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 0.0006535927592013421}\n",
      "Losses {'ner': 1.2728909784336284}\n",
      "Losses {'ner': 19.234741273561404}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SurafelT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"Fear the walking dead,Supernatural (huge fan and s...\" with entities \"[(85, 94, 'Movie_Show_Titles'), (70, 83, 'Movie_Sh...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 19.234819016233278}\n",
      "Losses {'ner': 5.920956446019839}\n",
      "Losses {'ner': 5.92096343075455}\n",
      "Losses {'ner': 2.961780950514288}\n",
      "Losses {'ner': 2.9617810814022745}\n",
      "Losses {'ner': 1.3283611132283022e-09}\n",
      "Losses {'ner': 3.793948932436468}\n",
      "Losses {'ner': 0.0007439994851964275}\n",
      "Losses {'ner': 1.354505801537168}\n",
      "Losses {'ner': 0.0003145630991667814}\n",
      "Losses {'ner': 1.3460260736468397}\n",
      "Losses {'ner': 3.322381851598655e-07}\n",
      "Losses {'ner': 0.9070113753810878}\n",
      "Losses {'ner': 0.4309020247381171}\n",
      "Losses {'ner': 0.43092953154817254}\n",
      "Losses {'ner': 1.694827023568131}\n",
      "Losses {'ner': 1.6981200102628475}\n",
      "Losses {'ner': 0.27591652550804635}\n",
      "Losses {'ner': 0.27660825126305166}\n",
      "Losses {'ner': 7.222739803670015e-07}\n",
      "Losses {'ner': 0.002118568362661769}\n",
      "Losses {'ner': 0.0004506372694007022}\n",
      "Losses {'ner': 0.4953172382733111}\n",
      "Losses {'ner': 4.389336957745914e-09}\n",
      "Losses {'ner': 1.1029082841880111}\n",
      "Losses {'ner': 1.1357048622013453}\n",
      "Losses {'ner': 1.1357056658310527}\n",
      "Losses {'ner': 0.0024877874269976855}\n",
      "Losses {'ner': 0.0024877940786981415}\n",
      "Losses {'ner': 9.058600878106627e-06}\n",
      "Losses {'ner': 2.555777509590766}\n",
      "Losses {'ner': 1.2016562219599509e-08}\n",
      "Losses {'ner': 0.46358977301495996}\n",
      "Losses {'ner': 0.008021623240068788}\n",
      "Losses {'ner': 0.008042178260738558}\n",
      "Losses {'ner': 0.00018851539283411498}\n",
      "Losses {'ner': 0.00019020876495571136}\n",
      "Losses {'ner': 0.0029030544275249503}\n",
      "Losses {'ner': 0.03161218125283137}\n",
      "Losses {'ner': 0.0006431771024267806}\n",
      "Losses {'ner': 0.003754115205368579}\n",
      "Losses {'ner': 0.1190610713589274}\n",
      "Losses {'ner': 0.11906326456896504}\n",
      "Losses {'ner': 2.113302647594734e-10}\n",
      "Losses {'ner': 1.698064477110996e-05}\n",
      "Losses {'ner': 1.4739657923319187e-06}\n",
      "Losses {'ner': 1.891959191718495e-06}\n",
      "Losses {'ner': 1.434050517751856e-11}\n",
      "Losses {'ner': 2.536469853295614e-05}\n",
      "Losses {'ner': 2.700361656673224e-10}\n",
      "Losses {'ner': 0.0013505088808786737}\n",
      "Losses {'ner': 0.00011371197423807226}\n",
      "Losses {'ner': 0.00011371204156688082}\n",
      "Losses {'ner': 8.678518512968642e-07}\n",
      "Losses {'ner': 0.007732586499202185}\n",
      "Losses {'ner': 3.374504945347031e-06}\n",
      "Losses {'ner': 3.3750304706731156e-06}\n"
     ]
    }
   ],
   "source": [
    "# Import requirements\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "from spacy.training.example import Example\n",
    "\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(unaffected_pipes):\n",
    "\n",
    "  # Training for 30 iterations\n",
    "  for iteration in range(30):\n",
    "\n",
    "    # shuufling examples  before every iteration\n",
    "    random.shuffle(train_data)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in spacy.util.minibatch(train_data, size=2):\n",
    "        for text, annotations in batch:\n",
    "        # create Example\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "        # Update the model\n",
    "            nlp.update([example], losses=losses, drop=0.5)\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on new texts the model has not seen\n",
    "\n",
    "Our NER's training is now complete. We can now see if the NER is functioning as planned. We'll need more examples and try again if it doesn't meet our expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "text = list()\n",
    "label = []\n",
    "for i in range(0,len(survey_responses)):\n",
    "    default_entities = nlp(survey_responses.iloc[i,1])\n",
    "    for ent in default_entities.ents:\n",
    "        text.append(ent.text)\n",
    "        label.append(ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fear the walking dead</td>\n",
       "      <td>Movie_Show_Titles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supernatural</td>\n",
       "      <td>Movie_Show_Titles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Outlander</td>\n",
       "      <td>Movie_Show_Titles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vikings</td>\n",
       "      <td>Movie_Show_Titles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Movie_Show_Titles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vikings</td>\n",
       "      <td>Movie_Show_Titles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Text              Label\n",
       "0  Fear the walking dead  Movie_Show_Titles\n",
       "1           Supernatural  Movie_Show_Titles\n",
       "2              Outlander  Movie_Show_Titles\n",
       "3                Vikings  Movie_Show_Titles\n",
       "4              Sometimes  Movie_Show_Titles\n",
       "5                Vikings  Movie_Show_Titles"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output = pd.DataFrame({'Text':text,'Label':label})\n",
    "Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above demonstrates that the model is not bad and has accurately spotted the titles, but not all of them. As a result, we must train the model with more examples in order to extract more data from the survey."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17aa2b9c05174fd5045e1cec7f75e566dfb72d3ff4eb7c49307d987556b141a3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
