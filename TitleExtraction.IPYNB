{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy \n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "spaCy is an open-source library for NLP. It is widely used because of its flexible and advanced features. Before diving into NER is implemented in spaCy, lets start by understanding what a Named Entity rEcognizer is.\n",
    "\n",
    "Named Entity Recognition is a standard NLP task that can identify entities discussed in the a text document. A Named Entity Recognizer is a model that can do this recognizing task. It should be able to identify named entities like 'New Zealand', 'John','Auckland', etc.. and categorize them as a PERSON, LOCATION, and so on. It is a very useful tool and helps in information Retrival. In sapCy, NER is implemented by pipeline component ner. Most of the models have it in their processing pipeline by default. \n",
    "\n",
    "First we start by installing the packages and see if the ner model is in our package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load a spacy model and check if it has ner (pre trained model for Named Entity Recognizer)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, NER is in the pipeline and we can proceed to categorize our entities based on the baseline mode, or already a pre trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom NER model\n",
    "\n",
    "As we saw, spaCy has in-built pipeline ner for NER. Although it performs well, it is not always completely accurate for your text. Sometimes, a word can be categorized as a PERSON or a ORG depending upon the context. Also, sometimes the category we want may not be built-in in spaCy.\n",
    "\n",
    "Lets have a look at how the default NER performs survey responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the survey file\n",
    "survey_responses = pd.read_csv(\"Survey response sample data.csv\")\n",
    "survey_responses = pd.DataFrame(survey_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "label = []\n",
    "for i in range(0,len(survey_responses)):\n",
    "    default_entities = nlp(survey_responses.iloc[i,1])\n",
    "    for ent in default_entities.ents:\n",
    "        text.append(ent.text)\n",
    "        label.append(ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gentlemen, Outlander</td>\n",
       "      <td>WORK_OF_ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dublin</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neon</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Undoing</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CB Strike</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>British</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Text        Label\n",
       "0  Gentlemen, Outlander  WORK_OF_ART\n",
       "1                London          GPE\n",
       "2                Dublin          GPE\n",
       "3                  Neon          ORG\n",
       "4               Undoing          ORG\n",
       "5             CB Strike       PERSON\n",
       "6               British         NORP"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output = pd.DataFrame({'Text':text,'Label':label})\n",
    "Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above in the table, the default NER is recognizing some of the entities wrong. For instance, it is categorizing CB Strike to be a PERSON and Undoing to be ORG. Also, there are a lot more movie or show titles, such as Fear the walking dead, Supernatural and others that have not been categorized in WORK_OF_ART category. In case like tis, we will have the need to update and train the NER model as per the context and requirements. In the next section, it is shown how to do it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the Named Entity Recognizer\n",
    "\n",
    "In the previous section, we saw why we need to update and train the NER. Now lets go a head and see how to do it.\n",
    "\n",
    "Our task is make sure the NER recognizes the movie titles as MOVIE. To enable this, we need to provide training examples which will make the NER learn for future samples. To do this, lets use an existing pre trained spaCy model and update it with newer examples. First, lets load a pre existing spaCY model with an in-built ner component. Then get the Named Entity Recognizer using get_pipe() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pre-existing spacy model\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#getting the pipeline component\n",
    "ner = nlp.get_pipe(\"ner\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to update the pre-trained model with new examples, we will have to provide many examples to meaningfully improve the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the training examples\n",
    "\n",
    "spaCy accepts training data as list of tuples.\n",
    "\n",
    "Each tuple should contain the text and dictionary. The dictionary should hold the start and end indices of the named entity in the text and the category or label of the named entity.\n",
    "\n",
    "For example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, creating a trining set manually is exhausting and consumes a lot of time. I am using a tool developed by https://github.com/ManivannanMurugavel/spacy-ner-annotator to create a training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add these labels to the ner.add_label() method of pipeline. Below code demonstrates the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the converter script\n",
    "import convert_spacy_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training format\n",
    "train_data = [('Fear the walking dead,Supernatural (huge fan and sad it has finished),The Gentlemen, Outlander', {'entities': [(85, 94, 'Movie_Show_Titles'), (70, 83, 'Movie_Show_Titles'), (22, 34, 'Movie_Show_Titles'), (0, 21, 'Movie_Show_Titles')]}), ('Miss scarlet and the duke,knifes out,Dublin murders', {'entities': [(51, 37, 'Movie_Show_Titles'), (36, 26, 'Movie_Show_Titles'), (25, 0, 'Movie_Show_Titles')]}), ('A lot!-good doctor-gangs of London�\\xa0- the gentleman-ma�\\xa0-spies in disguise�\\xa0', {'entities': [(73, 55, 'Movie_Show_Titles'), (53, 51, 'Movie_Show_Titles'), (50, 37, 'Movie_Show_Titles'), (34, 19, 'Movie_Show_Titles'), (18, 7, 'Movie_Show_Titles')]}), ('The Undoing,Game of thrones,Outlander, Vikings,CB Strike (and most all British dramas) Westworld', {'entities': [(56, 47, 'Movie_Show_Titles'), (39, 46, 'Movie_Show_Titles'), (37, 28, 'Movie_Show_Titles'), (27, 12, 'Movie_Show_Titles'), (11, 0, 'Movie_Show_Titles')]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding labels to the ner\n",
    "for _, __annotations__ in train_data:\n",
    "    for ent in __annotations__.get('entities'):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train the NER over these examples. But before we train, remember from part from ner, the model has other pipeline components. These components should not get affected in training. Hence, we disable the other pipeline components through nlp.disable_pipes() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable pipeline components you dont need to change\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the model with unaffected_pipes disabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 0.0006535927592013421}\n",
      "Losses {'ner': 1.2728909784336284}\n",
      "Losses {'ner': 19.234741273561404}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SurafelT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\spacy\\training\\iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"Fear the walking dead,Supernatural (huge fan and s...\" with entities \"[(85, 94, 'Movie_Show_Titles'), (70, 83, 'Movie_Sh...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 19.234819016233278}\n",
      "Losses {'ner': 5.920956446019839}\n",
      "Losses {'ner': 5.92096343075455}\n",
      "Losses {'ner': 2.961780950514288}\n",
      "Losses {'ner': 2.9617810814022745}\n",
      "Losses {'ner': 1.3283611132283022e-09}\n",
      "Losses {'ner': 3.793948932436468}\n",
      "Losses {'ner': 0.0007439994851964275}\n",
      "Losses {'ner': 1.354505801537168}\n",
      "Losses {'ner': 0.0003145630991667814}\n",
      "Losses {'ner': 1.3460260736468397}\n",
      "Losses {'ner': 3.322381851598655e-07}\n",
      "Losses {'ner': 0.9070113753810878}\n",
      "Losses {'ner': 0.4309020247381171}\n",
      "Losses {'ner': 0.43092953154817254}\n",
      "Losses {'ner': 1.694827023568131}\n",
      "Losses {'ner': 1.6981200102628475}\n",
      "Losses {'ner': 0.27591652550804635}\n",
      "Losses {'ner': 0.27660825126305166}\n",
      "Losses {'ner': 7.222739803670015e-07}\n",
      "Losses {'ner': 0.002118568362661769}\n",
      "Losses {'ner': 0.0004506372694007022}\n",
      "Losses {'ner': 0.4953172382733111}\n",
      "Losses {'ner': 4.389336957745914e-09}\n",
      "Losses {'ner': 1.1029082841880111}\n",
      "Losses {'ner': 1.1357048622013453}\n",
      "Losses {'ner': 1.1357056658310527}\n",
      "Losses {'ner': 0.0024877874269976855}\n",
      "Losses {'ner': 0.0024877940786981415}\n",
      "Losses {'ner': 9.058600878106627e-06}\n",
      "Losses {'ner': 2.555777509590766}\n",
      "Losses {'ner': 1.2016562219599509e-08}\n",
      "Losses {'ner': 0.46358977301495996}\n",
      "Losses {'ner': 0.008021623240068788}\n",
      "Losses {'ner': 0.008042178260738558}\n",
      "Losses {'ner': 0.00018851539283411498}\n",
      "Losses {'ner': 0.00019020876495571136}\n",
      "Losses {'ner': 0.0029030544275249503}\n",
      "Losses {'ner': 0.03161218125283137}\n",
      "Losses {'ner': 0.0006431771024267806}\n",
      "Losses {'ner': 0.003754115205368579}\n",
      "Losses {'ner': 0.1190610713589274}\n",
      "Losses {'ner': 0.11906326456896504}\n",
      "Losses {'ner': 2.113302647594734e-10}\n",
      "Losses {'ner': 1.698064477110996e-05}\n",
      "Losses {'ner': 1.4739657923319187e-06}\n",
      "Losses {'ner': 1.891959191718495e-06}\n",
      "Losses {'ner': 1.434050517751856e-11}\n",
      "Losses {'ner': 2.536469853295614e-05}\n",
      "Losses {'ner': 2.700361656673224e-10}\n",
      "Losses {'ner': 0.0013505088808786737}\n",
      "Losses {'ner': 0.00011371197423807226}\n",
      "Losses {'ner': 0.00011371204156688082}\n",
      "Losses {'ner': 8.678518512968642e-07}\n",
      "Losses {'ner': 0.007732586499202185}\n",
      "Losses {'ner': 3.374504945347031e-06}\n",
      "Losses {'ner': 3.3750304706731156e-06}\n"
     ]
    }
   ],
   "source": [
    "# Import requirements\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "from spacy.training.example import Example\n",
    "\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(unaffected_pipes):\n",
    "\n",
    "  # Training for 30 iterations\n",
    "  for iteration in range(30):\n",
    "\n",
    "    # shuufling examples  before every iteration\n",
    "    random.shuffle(train_data)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in spacy.util.minibatch(train_data, size=2):\n",
    "        for text, annotations in batch:\n",
    "        # create Example\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "        # Update the model\n",
    "            nlp.update([example], losses=losses, drop=0.5)\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on new texts the model has not seen\n",
    "\n",
    "Training of our NER is completed now. We can test if the NER is now working as we expected. If it is not up to our expectations, we will need more examples and try again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "text = []\n",
    "label = []\n",
    "for i in range(0,len(survey_responses)):\n",
    "    default_entities = nlp(survey_responses.iloc[i,1])\n",
    "    for ent in default_entities.ents:\n",
    "        text.append(ent.text)\n",
    "        label.append(ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Vikings', 'Movie_Show_Titles')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(survey_responses.iloc[4,1])\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the model has extracted few"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17aa2b9c05174fd5045e1cec7f75e566dfb72d3ff4eb7c49307d987556b141a3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
